<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="SIMstack">
    <meta name="author" content="Zoe Landgraf">

    <title>SIMstack: A Generative Shape and Instance Model for Unordered Object Stacks</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>SIMstack: A Generative Shape and Instance Model for Unordered Object Stacks</h2>
    <h3></h3>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p class="authors">
        <a> Zoe Landgraf, Raluca Scona, Tristan Laidlow, Stephen James, Stefan Leutenegger, Andrew J. Davison</a>
    </p>

</div>

<div class="container">
    <div class="section">
        <div class="row align-items-center">
            <img src="img/Teaser_Image.png" style="width:100%">
<!--            <iframe class='video' src="https://www.youtube.com/embed/Q2fLWGBeaiI" frameborder="0"-->
<!--                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"-->
<!--                    allowfullscreen></iframe>-->
        </div>
        <hr>
        <p>
             By estimating 3D shape and instances from a single view, we can capture information about an environment
            quickly, without the need for comprehensive scanning and multi-view fusion. Solving this task for composite
            scenes (such as object stacks) is challenging: occluded areas are not only ambiguous in shape but also in
            instance segmentation; multiple decompositions could be valid. We observe that physics constrains
            decomposition as well as shape in occluded regions and hypothesise that a latent space learned from scenes
            built under physics simulation can serve as a prior to better predict shape and instances in occluded
            regions. To this end we propose SIMstack, a depth-conditioned Variational Auto-Encoder (VAE), trained on
            a dataset of objects stacked under physics simulation. We formulate instance segmentation as a centre
            voting task which allows for class-agnostic detection and doesn't require setting the maximum number of
            objects in the scene. At test time, our model can generate 3D shape and instance segmentation from a single
            depth view, probabilistically sampling proposals for the occluded region from the learned latent space.
        </p>
    </div>
    <div class="section">
        <h2>Learning a joint shape and instance encoding for object stacks</h2>
    </div>
</div>

    </body>
</html>